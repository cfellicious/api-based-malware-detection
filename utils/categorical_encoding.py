import os
import json
import zipfile
import numpy as np
from utils.utils import get_data
from tqdm import tqdm


def encode_count(call_list, data, keys):
    feature_vector = np.zeros(len(call_list), dtype=np.uint16)
    for line in data:
        input_line = json.loads(line)
        curr_fun = input_line.get(keys[0], input_line.get(keys[1], None))
        if curr_fun is not None:
            call_index = call_list.get(curr_fun.lower(), None)
            feature_vector[call_index] = feature_vector[call_index] + 1

    return feature_vector


def encode_count_length(unigram_list, bigram_list, trigram_list, data, keys, length):
    count = length
    unigram_vector = np.zeros(len(unigram_list), dtype=np.uint16)
    bigram_vector = np.zeros(len(bigram_list), dtype=np.uint16)
    trigram_vector = np.zeros(len(trigram_list), dtype=np.uint16)

    curr_bigram = []
    curr_trigram = []

    for idx, line in enumerate(data):
        input_line = json.loads(line)
        # curr_fun = input_line.get(keys[0], input_line.get(keys[1], None))
        curr_fun = input_line.get(keys[0], None)
        if curr_fun is not None:
            call_index = unigram_list.get(curr_fun.lower(), None)
            unigram_vector[call_index] = unigram_vector[call_index] + 1
            curr_bigram.append(curr_fun)
            curr_trigram.append(curr_fun)
            if len(curr_bigram) >= 2:
                bigram_call = curr_bigram[0] + curr_bigram[1]
                bigram_idx = bigram_list.get(bigram_call)
                bigram_vector[bigram_idx] += 1
                curr_bigram.pop(0)

            if len(curr_trigram) >= 3:
                trigram_call = curr_trigram[0] + curr_trigram[1] + curr_trigram[2]
                trigram_idx = trigram_list.get(trigram_call)
                trigram_vector[trigram_idx] += 1
                curr_trigram.pop(0)

            count -= 1
            if count == 0:
                return unigram_vector, bigram_vector, trigram_vector

    return unigram_vector, bigram_vector, trigram_vector


def generate_data_categorical_encoding(files, label_dict, client, bucket_name, temp_path, temp_dir, max_label, keys,
                                       call_dict, block_size=1000, single_label=True):

    block_size = min(len(files), block_size)
    dataset = np.zeros((block_size,len(call_dict)), dtype=np.uint16)
    labels = np.zeros((block_size, max_label), dtype=np.uint16)
    if single_label is True:
        labels = np.zeros(block_size, dtype=np.uint16)

    idx = 0
    for file in tqdm(files, desc='Files'):
        data = get_data(client=client, file=file)
        feature_vector = encode_count(call_list=call_dict, data=data, keys=keys)
        dataset[idx] = feature_vector
        if isinstance(file, str):
            sha = file
        else:
            sha = file.object_name.split(sep='-')[0]
            sha = sha.split(sep='/')[1]
        curr_labels = label_dict.get(sha)
        if single_label is True:
            labels[idx] = curr_labels[0]
        else:
            for label in curr_labels:
                labels[idx][label] = 1
        idx += 1

    return dataset, labels


def generate_length_based_categorical_encoding(files, label_dict, client, max_label, keys, call_dict, length,
                                               bigram_info, trigram_info, block_size=1000, single_label=True):

    block_size = min(len(files), block_size)
    unigram_dataset = np.zeros((block_size,len(call_dict)), dtype=np.uint16)
    bigram_dataset = np.zeros((block_size, len(bigram_info)), dtype=np.uint16)
    trigram_dataset = np.zeros((block_size, len(trigram_info)), dtype=np.uint16)
    labels = np.zeros((block_size, max_label), dtype=np.uint16)
    if single_label is True:
        labels = np.zeros(block_size, dtype=np.uint16)

    idx = 0
    for file in tqdm(files, desc='Files'):
        data = get_data(client=client, file=file)
        unigram_vector, bigram_vector, trigram_vector = encode_count_length(unigram_list=call_dict,
                                                                            bigram_list=bigram_info,
                                                                            trigram_list=trigram_info, data=data,
                                                                            keys=keys, length=length)
        unigram_dataset[idx] = unigram_vector
        bigram_dataset[idx] = bigram_vector
        trigram_dataset[idx] = trigram_vector

        if isinstance(file, str):
            sha = file
        else:
            sha = file.object_name.split(sep='-')[0]
            sha = sha.split(sep='/')[1]
        curr_labels = label_dict.get(sha)
        if single_label is True:
            labels[idx] = curr_labels[0]
        else:
            for label in curr_labels:
                labels[idx][label] = 1
        idx += 1
    """
    unigram_dataset = np.uint16(np.divide(unigram_dataset, np.reshape(np.sum(unigram_dataset, axis=1),
                                                                      newshape=(unigram_dataset.shape[0], 1))) * 100)
    bigram_dataset = np.uint16(np.divide(bigram_dataset, np.reshape(np.sum(bigram_dataset, axis=1),
                                                                    newshape=(bigram_dataset.shape[0], 1))) * 100)
    trigram_dataset = np.uint16(np.divide(trigram_dataset, np.reshape(np.sum(trigram_dataset, axis=1),
                                                                      newshape=(trigram_dataset.shape[0], 1))) * 100)
    """
    return unigram_dataset, bigram_dataset, trigram_dataset, labels


